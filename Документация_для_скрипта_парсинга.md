# Документация для скрипта парсинга на Unix сервере

Эта документация содержит пошаговые инструкции по настройке и запуску предоставленного скрипта парсинга на сервере Unix. Скрипт использует Selenium для парсинга данных о продуктах с Ozon и сохраняет данные в локальную базу данных SQLite.

## Необходимые условия

1. **Python 3.8+**: Убедитесь, что Python установлен на вашем сервере. Если нет, установите его с помощью:
    ```bash
    sudo apt-get update
    sudo apt-get install python3.8 python3-pip
    ```

2. **Chromedriver**: Скрипт требует Chromedriver для управления браузером Chrome. Установите Chromedriver, выполнив следующие шаги:
    ```bash
    sudo apt-get update
    sudo apt-get install -y chromium-chromedriver
    ```

3. **Google Chrome**: Убедитесь, что Google Chrome установлен на вашем сервере. Если нет, установите его с помощью:
    ```bash
    sudo apt-get update
    sudo apt-get install google-chrome-stable
    ```

4. **Python пакеты**: Установите необходимые Python пакеты с помощью pip:
    ```bash
    pip3 install selenium sqlite3
    ```

## Настройка скрипта

1. **Файл скрипта**: Сохраните предоставленный скрипт как `scraping_script.py` на вашем сервере.

2. **Входной файл**: Создайте файл под названием `SKU_Ozon.txt`, содержащий список артикулов продуктов (по одному на строку).

3. **Файл логов**: Убедитесь, что скрипт имеет права на создание и запись в `errors.log` для логирования ошибок.

## Запуск скрипта

### Ручной запуск

Вы можете запустить скрипт вручную, используя следующую команду:
```bash
python3 scraping_script.py
```

### Запланированный запуск с помощью Cron

Чтобы запускать скрипт периодически, вы можете настроить cron задачу. Например, чтобы запускать скрипт каждый час:

1. Отредактируйте файл crontab:
    ```bash
    crontab -e
    ```

2. Добавьте следующую строку, чтобы запланировать запуск скрипта каждый час:
    ```bash
    0 * * * * /usr/bin/python3 /path/to/scraping_script.py >> /path/to/scraping_log.txt 2>&1
    ```

Замените `/path/to/scraping_script.py` на фактический путь к вашему файлу скрипта и `/path/to/scraping_log.txt` на желаемый путь для файла журнала.

### Запуск в цикле

Если вы хотите, чтобы скрипт выполнялся непрерывно с задержкой между запусками, вы можете изменить функцию main следующим образом:

```python
# Основной цикл
if __name__ == "__main__":
    while True:
        print("Запуск парсинга...")
        main()
        print("Ожидание следующего цикла...")
        time.sleep(3600)  # Ожидание 1 часа перед следующим циклом
```

Эта модификация позволит скрипту выполняться непрерывно с задержкой в 1 час между каждым циклом.

## Устранение неполадок

1. **Проблемы с правами**: Убедитесь, что у скрипта и файла журнала есть необходимые разрешения для выполнения и записи.
2. **Зависимости**: Проверьте, что все необходимые зависимости установлены правильно.
3. **Путь к Chromedriver**: Убедитесь, что в скрипте указан правильный путь к Chromedriver.

## Заключение

Следуя этим шагам, вы сможете настроить и запустить предоставленный скрипт парсинга на сервере Unix. Скрипт будет парсить данные о продуктах с Ozon и сохранять их в локальную базу данных SQLite. Для любых проблем или дальнейшей настройки обратитесь к комментариям в скрипте и при необходимости внесите изменения в код.